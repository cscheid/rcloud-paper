\firstsection{Introduction}

\maketitle

\carlos{General plan: we take Kandel et al.'s interview study, and Heer and Agrawala design considerations, and make them integral to the explanation of RCloud, throughout the whole paper.}

\carlos{We need to remake all the figures, pretty much. They need to have real notebooks, on each and every one of them.}

\carlos{Update with new RCloud features. Multiple languages, full-text searching, shiny, ...}

%% \todo{Points we want to make."Coordination is done by meetings" "how do you trace an automated alert back to an EDA environment ?"}

% What's the area
Consider the emerging role of a data science team within an
organization today \cite{Keim:2008:VAS}.
%
% How do people do it today?
Individual data scientists and statisticians usually work on loosely
related problems, and must devise effective ways to share their findings
and move results from exploratory data analysis to automated reports and
diagnostics that are deployed for wider consumption.
They generally rely on a patchwork of resources shared informally,
or at best, through systems that attack individual tasks or functions
in the data analysis workcycle. % might cite information visualization reference model or pirolli/card

% Why does this not work?
There are two problems with the current practice. First, there are
gaps in the workflow: Exploratory Data Analysis (EDA) is done with one
set of tools, and automated reports and deployments with another. This
makes transferring results between EDA and production slow, expensive,
and error-prone, in both directions. Coordination is done through meetings
and may take months to carry out.

Second, EDA environments often assume a single-developer perspective,
while data scientist teams could greatly benefit from convenient searching
and sharing of scripts, data sets, data feeds, experiments, annotations,
and automated analyses and recommendations. These capabilities have had
extraordinary impact on information retrieval in general, but are well
beyond what existing visual analytics environments provide, or what
is found in today's repositories and version control
systems.\cite{Koren:2009:FIT}

In addition, consider trends in interactive visualization software
in the open source community.  Projects led by Jeff Heer
include Prefuse, Flare, Protovis, d3, and Vega, in that order.
All but the first of these libraries take advantage of web technologies,
and all but the second rely on open standards. Hadley Wickham is the
author of ggplot, ggplot2, and ggvis. ggplot and ggplot2 generate
static graphics, while ggvis provides convenient interactive visualizations
in R, using the R package Shiny and the Vega abstract visualization grammar,
opening a separate web server for each call. These projects show
a trend toward visual analytics frameworks and systems that are
increasingly rich, interactive, composable, and accessible through the web.

% What are we going to do about this?

%% \todo{Define the requirements for the system}
%% We begin by noting the main requirements for a data analysis
%% environment for collaboration and transfer of results into production.

%% Main requirement is to satisfy these two sets of users: R coders and
%% managers. They work differently and want different things. What should
%% the infrastructure look like so they both coexist in peace? If this is
%% such a fundamental problem, why have other tools not addressed it?
%% Discuss Shiny (maybe in the disc. section).

Today's state-of-the-art environments for data science teams are unquestionably
powerful, but also fragmented. Instead of creating a new solution that promotes
even further fragmentation, we attempt to identify and remedy the shortcomings
in the current practice of data science. The following requirements summarize
the main pain points:

\begin{enumerate}

\item Technology transfer. In our experience, development
of new analyses and visualizations is done by \emph{hackers}
and \emph{scripters} (using Kandel et al.'s
terminology~\cite{Kandel:2012:EDA}) who are, by definition,
at least somewhat familiar with programming and software development.
On the other hand, \emph{application
users} ultimately derive value from the data by means of the tools
developed by hackers and scripters. Traditionally, the connection
between these two worlds is made by IT staff. In an environment where
business needs can change every day, manual IT support does not scale:
we need to create software infrastructure to connect the two worlds.
%% The two classes of users
%% have quite different perspectives but we
%% infrastructure for continuous deployment of visualizations.

\item Coexistence. In the current data science ecosystem, the
isolation of exploratory visualization and data analysis
environments is a hinderance to wider adoption of modern techniques
on both sides. We specifically see the richness of interactive
visualization tools as still being isolated from the richness
of statistical programming environments.
%(The path backward from production to analysis can be 
%equally important: when problems discovered in
%production require expert help, we would like experts to be
%able to immediately apply the full range of analytic tools without
%extracting data to move it back to the EDA environment.)
There is an opportunity to provide a framework so that developments
on either side are more easily employed by the other.
In addition, the integrated results should be more easily accessible
to the rest of the organization.

\item Discoverability. From our experience in working with data
analyst teams, we find that repeated work (``How can I connect to
database X?'', ``How do you get clean data from column Y from feed
Z?'') arises from lack of communication about previously solved subproblems.
We wish to provide transparency about the work of team members in the organization.

\end{enumerate}

Technologies which fail to address these requirements
are holding back the practice and impact of interactive visual
analysis. In this paper, we discuss the design and deployment of
RCloud, a prototype environment that supports collaborative data
analysis, visualization and web deployment satisfying all requirements
above. We will report on the design decisions, tradeoffs and
limitations, and compare the concepts in RCloud to related proposals.

%% Our investigation focuses on the R language \cite{RCoreTeam:2013:R}
%% for statistical computing and graphics. R is one of the most popular
%% systems for data analysis and is well-supported by
%% a complex ecosystem of compatible packages, software
%% tools and other resources.
%
%% Of importance to us, there are existing
%% packages for high performance computing in the cloud,
%% and for generating web graphics. % no, there aren't. we wrote those!

RCloud uses the R language~\cite{RCoreTeam:2013:R} as the core set
of statistical analysis tools.  The facilities for \emph{sharing, viewing
and embedding} RCloud notebooks address the {\bf technology transfer} requrement.
Because RCloud embraces technologies that are part of the computing
environment (specifically, inter-process communication via HTTP and
web services as remote procedure calls, as explained
in Section~\ref{sec:highlevelarchitecture}), it is straightforward to
integrate RCloud with satellite efforts in corporate environments.

{\bf Coexistence} between analysis and visualization is supported in
its human interface architecture, described in~\ref{sec:humaninterface}. 
As oulined in Section~\ref{sec:notebooks}, RCloud notebooks are sequences
of R snippets interspersed with Markdown for easy generation of reports.
We describe how RCloud enables interactive visualization widgets in
this setting (Sections~\ref{sec:Rinbrowser} and~\ref{sec:interactivenotebooks}).
Indexing, publishing and sharing of notebooks is also the main way
Rcloud supports {\bf discoverability}.

The requirement of continuous technology transfer, though, creates challenges
about the \emph{stability} of the many moving pieces: if notebooks are
updated and deployed automatically, how can the system handle
changing requirements and public interfaces? We discuss our choice of
transparent, integrated version control for RCloud notebooks in 
Section~\ref{sec:deployment}.

Section~\ref{sec:casestudy} describes a case study illustrating some of these concepts.

In Section~\ref{sec:limitations}, we report on experience toward meeting
these requirements in RCloud, and limitations encountered.  

%% Dashboards are a solution to requirement 1, using solutions of
%% requirement 2.
%% Requirement 2: \emph{how is accessibility supposed to happen?}

%% Version control as a primary concept in the environment is a
%% consequence of requirement 1. There
%% needs to be a way to control the visibility of prototypes as they are
%% being developed and tested.

%% Tight integration between R process and web browser is a solution to
%% requirement 2

%% Current isolation notwithstanding, we find there is demand for interactive
%% visualization tools. We do not believe that moving the \

%% The main challenge here is how to integrate these
%% technologies so data scientists and statisticians can target
%% them, \emph{and} business-facing users can use them.
%% Scalable technologies like crossfilter exist. Want to support those in the context of an R environment. Need to support full 2-way communication between computing in the cloud and interaction on the web.
%% \item Other requirements e.g. Kandel's user study. Not our contribution but things we must address, mentioned in related work section. Heer/Agrawala design considerations for collaborative visual analytics.

% What is the scope of our solution?

% We want our solution to play well with the rest of the ecosystem
