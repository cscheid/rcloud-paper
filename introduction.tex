\firstsection{Introduction}

\maketitle

More than a half-century ago, Tukey foresaw
much of what is now commonplace in data analysis~\cite{TukeyFDA}.
Powerful, interactive environments for analysis and programming were
the goal, with unswerving insistence on visualization as a
central part of the discovery process. His now-famous quip that
``the picture-examining eye is the best finder we have of the
wholly unanticipated'' has come to define much of visual analytics
and exploratory visualization~\cite{TukeyEDA}.

Computing has moved far beyond what Tukey imagined.
Processing and networking capabilities today far exceed
what was barely imaginable then. Sophisticated technologies
for processing, storing, publishing, searching and sharing
information and analyses are commonplace.
But how we \emph{develop} analytic solutions has not changed much. 
Although environments such as RStudio include many features to
graphically interact with a local workspace, still follow the metaphor
of terminal, text editor, and source files stored in file systems.

The work of data scientists in teams is also changing.
Project teams vary in size, from just a few people to dozens or
more.
Assignments are broad and include tasks such as problem identification,
data wrangling, modeling, analysis, visualization, summarization,
presentation and interpretation of results, and recommending
actions to help clients to realize the benefits of the analysis.
Knowledge or software prototypes created by these teams are transferred
to other organizations to employ them in production.
This work depends extensively on communication and collaboration.
At almost every step, collaborators share detailed knowledge about tasks,
data and code.
Further, data scientists are increasingly asked to work closely
with less technically-oriented business or domain specialists.

Previous work has identified important areas for improvement in
visual analytics systems to address this situation.

\begin{enumerate}
\item Discoverability. A chronic complaint of data analysis teams is
inefficiency due to a lack of transparency in accessing the work of
other team memnbers.  The processes and technologies supporting
data analysis and visual analytics today are fragmented.
Knowledge is shared imperfectly through informal conversations, emails,
meetings, phone calls, source code, wikis and project documents.
This causes work to be repeated unnecessarily
(``How can I connect to database X?'', ``How do you get clean data
from column Y from feed Z?'') due to lack of communication about
previously solved problems. 
Our goal is support and
promote transparency of work between team members.

Results of experiments are often shared first by copying screen
shots or static output. By the time decisions are made based on
the results of that screenshot, data and processes may have changed
so much that the decision can be wrong.

\item Technology transfer.
In most organizations, development of analyses and visualizations 
s done by \emph{hackers} and \emph{scripters} (adopting Kandel et al.'s
terminology~\cite{Kandel:2012:EDA}). \emph{Application users} 
gain the benefits of the tools developed by hackers and scripters.
Results of experiments are often shared first by copying screen
shots or static output.  By the time decisions are made based on
the results of that screenshot, data and processes may have changed
so much that the decision can be wrong.
\stephen{Transitional sentence here.}
Generally, the connection between these two worlds is made by IT staff,
who port or rewrite code so it can run as a stable production service.
In an environment where business needs can change rapidly, this
process does not scale. It is also difficult to trace problems
from production back to EDA.
Our goal is to merge the worlds of EDA and production to close this gap.

\item Coexistence. In current ecosystems, the isolation of exploratory
visualization and data analysis environments hinders wider adoption of
modern techniques from each.
The richness of interactive visualization tools is still somewhat
separated from the power of statistical programming environments.
There is an opportunity to provide a framework so that developments
on each side are more easily adopted by the other, and made available
in production services.

\end{enumerate}

Fortunately, there is abundant evidance that technology can
solve many of these problems.
Gutierrez collected interviews with data scientists~\cite{Gutierrez:2014:DSA},
which include the following:

\begin{itemize}
\item (upon being given access to other code and data analysis, in
order to learn about Hadoop) ``I could look at other peopleâ€™s code
and play with their code and data sets as well''
\item (discussing the value of sharing prototypes rather than static
data) ``Prototyping our products so that internal
customers can use them early on has been crucial for
our success. Now we can shoot off a URL to internal
customers and it allows them to provide feedback way before
we're talking about getting it into production.''
\item (on sharing more than just a finished product) ``We also share
exploratory analyses and reports so that we can still exchange
knowledge even if the work didn't make it into a larger project.''
\item (on changing analyses and processes) ``It is important to
have testing frameworks so you can go back and test all
of your data.''
\end{itemize}

In consideration of the opportunity to improve this situation,
we created a software environment that supports the end-to-end
visual analytics process for individuals and teams and
their work within larger organizations.


In this paper, we contribute the
design of RCloud, with an interview study based on the
course of its development and deployment at AT\&T Labs for 
about three years.

This environment knits together some familiar tools, and 
provides new features to find data and code; create experimental workbooks;
run experiments; annotate and deploy experiments as end-user websites or
as reusable, callable services; and to share, search and recommend these artifacts. The artifacts are stored in a version
control system that provides a common workspace, as well as needed control
and isolation between stable and experimental versions of code and other
resources. 

A key point is that, for the most part, the improved capabilities are
available by default, without much explicit involvement on the part of
data scientists and other customers. Visual analytics experiments are
conveniently shared and turned into production websites, without moving
or porting code. All the published artifacts in the system can be
searched immediately. Recommendation is as easy as clicking a star
on a useful workbook.

The high level architecture of the prototype system
is shown in figure~\ref{fig:system}.
We chose R as the foundation for our prototype because it is already
the dominant statistical computing language in our lab.
R also has many useful packages for data analysis and visualization,
and the core system and its packages are open source that can be modified to
support research. 

Over the past three years, we prototyped RCloud and deployed it to
a community of data scientists, business analysts and other colleagues.  The
platform today has over 300 active accounts; about 20 people use it regularly,
another 30 people use it more than once a week, and another 50 use it more than
once a month.  Most of the
active users are members of AT\&T Labs, but some are data scientists and other
collaborators in other business units.
