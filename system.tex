\section{The System\label{sec:system}}

One of the starting points in our design goals was to leverage, as
much as possible, the current infrastructure of the world-wide
web. HTTP, with all its warts, has become the lingua franca of
distributed interprocess communication. This meant that if our system
spoke HTTP natively, then it was possible to provide a low-friction
path from development of an interactive data analysis script to an
automated \emph{web service}, essentially a function call over the
web, which can then be used in higher-level tools. An example of this
kind of transition is described in Section~\ref{sec:casestudy}.

As a result, the entire high-level infrastructure of RCloud, shown in
Figure~\ref{sec:system} uses web standards. The communication between
the web browser and the active R session as a user edits a notebook is
a combination of HTTP and Websockets, while all other IPC happens
through HTTP, from notebook versioning in GitHub to building and
maintaining full-text indices through SOLR. The most peculiar feature of RCloud's runtime system is its tight integration between the web browser and the backend R process, which we describe in Section~\ref{sec:Rinbrowser}.

\subsection{Notebooks\label{sec:notebooks}}

The main unit of computation in RCloud is a \emph{notebook}.  A
notebook holds a sequence of \emph{cells}, each of which is a snippet
of code or hypertext in Markdown. As mentioned in
Section~\ref{sec:related}, this is not a novel idea: executable
documents structured this way are a feature of many other systems,
including Mathematica, IPython and Sage.

Notebooks can be executed one cell at a time during an interactive
editing session, providing a similar experience to traditional
read-eval-print loops, or can also be executed all at once, providing
a similar experience to running a shell script.

One of the main contributions of RCloud is the idea that notebooks are
``always deployed''. In other words, the most recent version of a
notebook is immediately available to all other users of the system as
the notebook is being developed. One way to describe this is that
RCloud lacks a ``save'' button: any notebook cell that runs is always
associated to a notebook version serialized to disk. Although one of
the interviewed users reports that this sometimes leads to an
excessively fine-grained sequence of versions (see
Section~\ref{sec:interviews}), we believe that the alternative of
losing automatic sharing is worse (and see
Section~\ref{sec:interviews} again for users reporting their
satisfaction over the low-friction shareability).

When we combine this with the ability to refer to the latest version
of a notebook by name, we get notebooks that are always live, but
sometimes broken. When stability is important, we also
allow any previous version of a notebook to be tagged and referred
to. These are similar to models like Jankun-Kelly et al.'s p-set calculus
\cite{Jankun-Kelly:2007:MFV} and VisTrails's version tree
\cite{Callahan:2006:VVM}, where every change in the state of the
system is tracked.

Our implementation of the versioning mechanism is built on
top of GitHub's \emph{gists}~\cite{GitHub:2014:GG}, which are an HTTP
interface for simplified repositories. The GitHub web-service API
provides most of the semantics we need for the versioning portion of
the storage back end: access to previous versions, comments, starring,
and forking. This provides the additional benefeit that every RCloud
notebook can also be manipulated like a git repository. Advanced users
then have access to features like command-line checkout, history
editing, and so on.

\subsection{Reputation and Interest: starring\label{sec:starring}}

One side advantage of centralizing the execution and storage of
notebooks is that it becomes feasible to collect usage information
that would otherwise be lost. In the case of social data visualization
platforms, we would like to leverage this usage data to help analysts
find content of interest, whether this content is actual source code
or accompanying data. The standard way to achieve this is through
\emph{user-generated curation} and \emph{automatic recommendations}.

Automatic recommendations have become famous in the user experience
provided by companies such as Amazon and Netflix (``if you've liked
this film, then you'll like this other film''). In order to build such
recommendations, we need users to \emph{curate} the collection, by
providing explicit reviews or some other method of indicating interest.
%%
%% In RCloud, reputation and interest are a relationship between
%% \emph{notebooks} and \emph{users}, rather than a relationship between
%% user pairs. We chose this approach because we expect initial 
%% RCloud deployments to have relatively few users, but some users to
%% create many notebooks. Under that assumption, assigning interest
%% to users would not provide sufficiently ``high-resolution'' data.
%%
We incorporate both explicit and implicit indications of interest
in notebooks. Explicit interest is indicated by ``starring,'' or
clicking on a button that marks a notebook as interesting.
This makes explicit indication of interest a nearly trivial operation,
always readily available, to encourage its use.
%
The current version of RCloud uses only simple aggregate counts of
stars to indicate overall notebook interest, mostly because the
recommendation system approaches popularized by the Netflix prize
require large recommendation sets to paying off. Nevertheless, the
starring mechanism is sufficient to create personalized
recommendations~\cite{Hu:2008:CFF}.

Implicit signaling of interest is supported by keeping click-through
counts~\cite{Joachims:2005:AIC} and execution counts. In addition to
these standard techniques of collecting feedback from web search, we
anticipate applying static and dynamic code analysis to infer
fine-grained information about relationships, for example, which
packages and data sets often appear together, in the style of Fast et
al's Codex system.~\cite{Fast:2014:ECS}.

\subsection{Deployment of notebooks\label{sec:deployment}}

Every notebook in RCloud is named by a URL, and notebooks by default
are visible by the entire organization. This is deliberate.  As
pointed out by Wattenberg and Kriss~\cite{Wattenberg:2011:DFS}, broad
access to analysis outputs (in their case, for NameVoyager) increases
long-term engagement in part through cross-references on the
web. Although our prototype RCloud deployment is only visible inside a
corporate intranet, we nevertheless found support for this notion by
discovering links to RCloud notebooks in internal discussion fora and
mailing lists. In addition, as we describe in
Section~\ref{sec:interviews}, users have almost unanimously adopted
``share-by-URL'' as their default communication mechanism, as opposed
to ``share-by-screenshot'', which we consider to be an encouraging
validation of the system.

\subsection{Executing R through a web browser, and Javascript through an R process\label{sec:Rinbrowser}}

As mentioned before, the other main goal in RCloud was to provide, as
much as possible, full access to the R programming language during the
\emph{development} of a data analysis notebook.
At the same time, when notebooks are \emph{deployed} (and potentially
accessed by anyone with a web browser), we'd like to allow a web
browser to invoke only a very limited subset of R, namely those
notebooks that have been published.

The solution we have developed is simple and general, and is directly
inspired by Miller's \emph{object
  capabilities}~\cite{Miller:2006:RCT}. Specifically, the R layer that
communicates with javascript does not expose naked evaluation of
arbitrary functions. Instead, every function that the R layer intends
to expose is associated with a large, cryptographically-safe random
number (informally, a ``hash''). This random number is then sent
across the wire. This number is interpreted as an opaque identifier to
a function. Because these identifiers are cryptographically safe, all
that the Javascript layer can do is return them to the R side, in a
message requesting that this function be called on its behalf. In that
case, the results of this function call might include \emph{new}
opaque identifiers, exposing new ``capabilities'' to the web browser.

The same idea of exposing functionality via hashes can be used to give
the server-side of RCloud access to Javascript functions. This allows
R libraries to respond to user input in the browser, giving them
access to features ranging from password prompts to the currently
selected set of points in an interactive linked brushing
visualization.

As a result, the features required to provide safe access to R from
the client side, and Javascript access from the R side, also enable
full two-way communication between the languages.  This provides
considerable flexibility so that for example, a chart built with dc.js
or leaflet.js can call back to analysis functions in R without having
to define an additional protocol between the processes. From the
Javascript side, an RPC call into the R process is just another HTTP
request. From the R process, a call into Javascript looks is just
another function call.
